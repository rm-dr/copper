[paths]
# All paths are relative to the location of this file.
#
# The last component of each path will be created automatically.
# if any parents are missing, Copper will not start.

# In-progress uploads are stored here. This shouldn't be a ramdisk,
# files have an arbitrary size.
# THIS DIRECTORY IS CLEARED EVERY TIME THE SERVER STARTS.
upload_dir = "./tmp"

# Where to store datasets. Will get pretty big.
dataset_dir = "./datasets"

# Path to main database file.
main_db = "./copper.sqlite"


[network]
# Address and port to bind to
server_addr = "127.0.0.1:3030"

# Max request body size, in bytes
# If you're using a reverse proxy, make sure it
# is also configured for requests of this size.
request_body_limit = 2_000_000

# How long login tokens stay valid
#
# This is a value in hours and should be positive.
# If this zero (or smaller), logins to not expire.
#
# 168 = 7 * 24
login_lifetime = 168

# Maximum number of items to return in one page
#
# If this is zero, there is no limit.
# (NOT RECOMMENDED)
max_item_page_size = 100



[pipeline]
# The maximum size, in bytes, of a binary fragment in the pipeline.
# Smaller values slow down pipelines; larger values use more memory.
# The default of 2mb is usually fine.
blob_fragment_size = 2_000_000

# Pipeline parallelism configuration.
# We'll run `parallel_jobs` jobs at once, allowing each to use at most
# `threads_per_job` threads.
#
# Note that a pipeline runner can't always utilize all the threads it is
# allowed to use. Therefore, the runner will rarely---if ever---use all
# `parallel_jobs * threads_per_job` threads it is allowed to start.
#
# It is probably a good idea to set `parallel_jobs` to *roughly* your cpu's core count.
# A large `threads_per_job` will rarely affect the performance of most workloads.
parallel_jobs = 4
threads_per_job = 4


[logging]
# Log level config.
# These defaults make sense unless you're tracking down a bug.
#
# - sqlx: Log level for sqlx (sql queries)
# - http: Log level for axum (web server)
# - pipeline: Log level for pipeline runner
# - server: Log level for copperd core (auth, api, etc)
# - dataset: Log level for dataset operations
# - all: Log level for all other sources. This can get noisy.
level.sqlx = "Info"
level.http = "Info"
level.pipeline = "Info"
level.server = "Info"
level.dataset = "Info"
level.migrate = "Info"
level.all = "Warn"
